{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasMMoE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m46XuyJnYBrU"
      },
      "source": [
        "#Samer Baslan\n",
        "#CMPE-297: Meta-Learning and Multi Learning Assignment\n",
        "#Keras MMoE\n",
        "\n",
        "Resource: https://github.com/drawbridge/keras-mmoe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR9-_TDQY_xk"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL_KSRSaXErY"
      },
      "source": [
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import activations, initializers, regularizers, constraints\n",
        "from tensorflow.keras.layers import Layer, InputSpec"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-GCmTxTZCwq"
      },
      "source": [
        "##Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDpf0ougXliZ"
      },
      "source": [
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHKb-Gy3ZD4A"
      },
      "source": [
        "##MMoE class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9yj1pgkXoZf"
      },
      "source": [
        "class MMoE(Layer):\n",
        "    \"\"\"\n",
        "    Multi-gate Mixture-of-Experts model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 units,\n",
        "                 num_experts,\n",
        "                 num_tasks,\n",
        "                 use_expert_bias=True,\n",
        "                 use_gate_bias=True,\n",
        "                 expert_activation='relu',\n",
        "                 gate_activation='softmax',\n",
        "                 expert_bias_initializer='zeros',\n",
        "                 gate_bias_initializer='zeros',\n",
        "                 expert_bias_regularizer=None,\n",
        "                 gate_bias_regularizer=None,\n",
        "                 expert_bias_constraint=None,\n",
        "                 gate_bias_constraint=None,\n",
        "                 expert_kernel_initializer='VarianceScaling',\n",
        "                 gate_kernel_initializer='VarianceScaling',\n",
        "                 expert_kernel_regularizer=None,\n",
        "                 gate_kernel_regularizer=None,\n",
        "                 expert_kernel_constraint=None,\n",
        "                 gate_kernel_constraint=None,\n",
        "                 activity_regularizer=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "         Method for instantiating MMoE layer.\n",
        "\n",
        "        :param units: Number of hidden units\n",
        "        :param num_experts: Number of experts\n",
        "        :param num_tasks: Number of tasks\n",
        "        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n",
        "        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n",
        "        :param expert_activation: Activation function of the expert weights\n",
        "        :param gate_activation: Activation function of the gate weights\n",
        "        :param expert_bias_initializer: Initializer for the expert bias\n",
        "        :param gate_bias_initializer: Initializer for the gate bias\n",
        "        :param expert_bias_regularizer: Regularizer for the expert bias\n",
        "        :param gate_bias_regularizer: Regularizer for the gate bias\n",
        "        :param expert_bias_constraint: Constraint for the expert bias\n",
        "        :param gate_bias_constraint: Constraint for the gate bias\n",
        "        :param expert_kernel_initializer: Initializer for the expert weights\n",
        "        :param gate_kernel_initializer: Initializer for the gate weights\n",
        "        :param expert_kernel_regularizer: Regularizer for the expert weights\n",
        "        :param gate_kernel_regularizer: Regularizer for the gate weights\n",
        "        :param expert_kernel_constraint: Constraint for the expert weights\n",
        "        :param gate_kernel_constraint: Constraint for the gate weights\n",
        "        :param activity_regularizer: Regularizer for the activity\n",
        "        :param kwargs: Additional keyword arguments for the Layer class\n",
        "        \"\"\"\n",
        "        # Hidden nodes parameter\n",
        "        self.units = units\n",
        "        self.num_experts = num_experts\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Weight parameter\n",
        "        self.expert_kernels = None\n",
        "        self.gate_kernels = None\n",
        "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
        "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
        "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
        "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
        "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
        "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
        "\n",
        "        # Activation parameter\n",
        "        self.expert_activation = activations.get(expert_activation)\n",
        "        self.gate_activation = activations.get(gate_activation)\n",
        "\n",
        "        # Bias parameter\n",
        "        self.expert_bias = None\n",
        "        self.gate_bias = None\n",
        "        self.use_expert_bias = use_expert_bias\n",
        "        self.use_gate_bias = use_gate_bias\n",
        "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
        "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
        "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
        "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
        "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
        "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
        "\n",
        "        # Activity parameter\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        # Keras parameter\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.supports_masking = True\n",
        "\n",
        "        super(MMoE, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for creating the layer weights.\n",
        "\n",
        "        :param input_shape: Keras tensor (future input to layer)\n",
        "                            or list/tuple of Keras tensors to reference\n",
        "                            for weight shape computations\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        input_dimension = input_shape[-1]\n",
        "\n",
        "        # Initialize expert weights (number of input features * number of units per expert * number of experts)\n",
        "        self.expert_kernels = self.add_weight(\n",
        "            name='expert_kernel',\n",
        "            shape=(input_dimension, self.units, self.num_experts),\n",
        "            initializer=self.expert_kernel_initializer,\n",
        "            regularizer=self.expert_kernel_regularizer,\n",
        "            constraint=self.expert_kernel_constraint,\n",
        "        )\n",
        "\n",
        "        # Initialize expert bias (number of units per expert * number of experts)\n",
        "        if self.use_expert_bias:\n",
        "            self.expert_bias = self.add_weight(\n",
        "                name='expert_bias',\n",
        "                shape=(self.units, self.num_experts),\n",
        "                initializer=self.expert_bias_initializer,\n",
        "                regularizer=self.expert_bias_regularizer,\n",
        "                constraint=self.expert_bias_constraint,\n",
        "            )\n",
        "\n",
        "        # Initialize gate weights (number of input features * number of experts * number of tasks)\n",
        "        self.gate_kernels = [self.add_weight(\n",
        "            name='gate_kernel_task_{}'.format(i),\n",
        "            shape=(input_dimension, self.num_experts),\n",
        "            initializer=self.gate_kernel_initializer,\n",
        "            regularizer=self.gate_kernel_regularizer,\n",
        "            constraint=self.gate_kernel_constraint\n",
        "        ) for i in range(self.num_tasks)]\n",
        "\n",
        "        # Initialize gate bias (number of experts * number of tasks)\n",
        "        if self.use_gate_bias:\n",
        "            self.gate_bias = [self.add_weight(\n",
        "                name='gate_bias_task_{}'.format(i),\n",
        "                shape=(self.num_experts,),\n",
        "                initializer=self.gate_bias_initializer,\n",
        "                regularizer=self.gate_bias_regularizer,\n",
        "                constraint=self.gate_bias_constraint\n",
        "            ) for i in range(self.num_tasks)]\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n",
        "\n",
        "        super(MMoE, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Method for the forward function of the layer.\n",
        "\n",
        "        :param inputs: Input tensor\n",
        "        :param kwargs: Additional keyword arguments for the base method\n",
        "        :return: A tensor\n",
        "        \"\"\"\n",
        "        gate_outputs = []\n",
        "        final_outputs = []\n",
        "\n",
        "        # f_{i}(x) = activation(W_{i} * x + b), where activation is ReLU according to the paper\n",
        "        expert_outputs = tf.tensordot(a=inputs, b=self.expert_kernels, axes=1)\n",
        "        # Add the bias term to the expert weights if necessary\n",
        "        if self.use_expert_bias:\n",
        "            expert_outputs = K.bias_add(x=expert_outputs, bias=self.expert_bias)\n",
        "        expert_outputs = self.expert_activation(expert_outputs)\n",
        "\n",
        "        # g^{k}(x) = activation(W_{gk} * x + b), where activation is softmax according to the paper\n",
        "        for index, gate_kernel in enumerate(self.gate_kernels):\n",
        "            gate_output = K.dot(x=inputs, y=gate_kernel)\n",
        "            # Add the bias term to the gate weights if necessary\n",
        "            if self.use_gate_bias:\n",
        "                gate_output = K.bias_add(x=gate_output, bias=self.gate_bias[index])\n",
        "            gate_output = self.gate_activation(gate_output)\n",
        "            gate_outputs.append(gate_output)\n",
        "\n",
        "        # f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x))\n",
        "        for gate_output in gate_outputs:\n",
        "            expanded_gate_output = K.expand_dims(gate_output, axis=1)\n",
        "            weighted_expert_output = expert_outputs * K.repeat_elements(expanded_gate_output, self.units, axis=1)\n",
        "            final_outputs.append(K.sum(weighted_expert_output, axis=2))\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for computing the output shape of the MMoE layer.\n",
        "\n",
        "        :param input_shape: Shape tuple (tuple of integers)\n",
        "        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.units\n",
        "        output_shape = tuple(output_shape)\n",
        "\n",
        "        return [output_shape for _ in range(self.num_tasks)]\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Method for returning the configuration of the MMoE layer.\n",
        "\n",
        "        :return: Config dictionary\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'num_experts': self.num_experts,\n",
        "            'num_tasks': self.num_tasks,\n",
        "            'use_expert_bias': self.use_expert_bias,\n",
        "            'use_gate_bias': self.use_gate_bias,\n",
        "            'expert_activation': activations.serialize(self.expert_activation),\n",
        "            'gate_activation': activations.serialize(self.gate_activation),\n",
        "            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n",
        "            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n",
        "            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n",
        "            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n",
        "            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n",
        "            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n",
        "            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n",
        "            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n",
        "            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n",
        "            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n",
        "            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n",
        "            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n",
        "        }\n",
        "        base_config = super(MMoE, self).get_config()\n",
        "\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h6F2iXXZG-B"
      },
      "source": [
        "##Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js5ibqHDXtRX"
      },
      "source": [
        "class ROCCallback(Callback):\n",
        "    def __init__(self, training_data, validation_data, test_data):\n",
        "        self.train_X = training_data[0]\n",
        "        self.train_Y = training_data[1]\n",
        "        self.validation_X = validation_data[0]\n",
        "        self.validation_Y = validation_data[1]\n",
        "        self.test_X = test_data[0]\n",
        "        self.test_Y = test_data[1]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_prediction = self.model.predict(self.train_X)\n",
        "        validation_prediction = self.model.predict(self.validation_X)\n",
        "        test_prediction = self.model.predict(self.test_X)\n",
        "\n",
        "        # Iterate through each task and output their ROC-AUC across different datasets\n",
        "        for index, output_name in enumerate(self.model.output_names):\n",
        "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
        "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
        "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
        "            print(\n",
        "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
        "                    output_name, round(train_roc_auc, 4),\n",
        "                    output_name, round(validation_roc_auc, 4),\n",
        "                    output_name, round(test_roc_auc, 4)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VfGsYJRZIS8"
      },
      "source": [
        "##Data prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_6B2bHYXwVb"
      },
      "source": [
        "def data_preparation():\n",
        "    # The column names are from\n",
        "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
        "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
        "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
        "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
        "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
        "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
        "\n",
        "    # Load the dataset in Pandas\n",
        "    train_df = pd.read_csv(\n",
        "        'data/census-income.data.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "    other_df = pd.read_csv(\n",
        "        'data/census-income.test.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "\n",
        "    # First group of tasks according to the paper\n",
        "    label_columns = ['income_50k', 'marital_stat']\n",
        "\n",
        "    # One-hot encoding categorical columns\n",
        "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
        "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
        "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
        "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                           'vet_question']\n",
        "    train_raw_labels = train_df[label_columns]\n",
        "    other_raw_labels = other_df[label_columns]\n",
        "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "\n",
        "    # Filling the missing column in the other set\n",
        "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
        "\n",
        "    # One-hot encoding categorical labels\n",
        "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "\n",
        "    dict_outputs = {\n",
        "        'income': train_income.shape[1],\n",
        "        'marital': train_marital.shape[1]\n",
        "    }\n",
        "    dict_train_labels = {\n",
        "        'income': train_income,\n",
        "        'marital': train_marital\n",
        "    }\n",
        "    dict_other_labels = {\n",
        "        'income': other_income,\n",
        "        'marital': other_marital\n",
        "    }\n",
        "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
        "\n",
        "    # Split the other dataset into 1:1 validation to test according to the paper\n",
        "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
        "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
        "    validation_data = transformed_other.iloc[validation_indices]\n",
        "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    test_data = transformed_other.iloc[test_indices]\n",
        "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    train_data = transformed_train\n",
        "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
        "\n",
        "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axHumDzsXxqN",
        "outputId": "9709bac1-393d-43aa-87e1-3ac9a26f0002"
      },
      "source": [
        "train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
        "num_features = train_data.shape[1]\n",
        "\n",
        "print('Training data shape = {}'.format(train_data.shape))\n",
        "print('Validation data shape = {}'.format(validation_data.shape))\n",
        "print('Test data shape = {}'.format(test_data.shape))\n",
        "\n",
        "# Set up the input layer\n",
        "input_layer = Input(shape=(num_features,))\n",
        "\n",
        "# Set up MMoE layer\n",
        "mmoe_layers = MMoE(\n",
        "    units=4,\n",
        "    num_experts=8,\n",
        "    num_tasks=2\n",
        ")(input_layer)\n",
        "\n",
        "output_layers = []\n",
        "# Build tower layer from MMoE layer\n",
        "for index, task_layer in enumerate(mmoe_layers):\n",
        "    tower_layer = Dense(\n",
        "        units=8,\n",
        "        activation='relu',\n",
        "        kernel_initializer=VarianceScaling())(task_layer)\n",
        "    output_layer = Dense(\n",
        "        units=output_info[index][0],\n",
        "        name=output_info[index][1],\n",
        "        activation='softmax',\n",
        "        kernel_initializer=VarianceScaling())(tower_layer)\n",
        "    output_layers.append(output_layer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape = (199523, 499)\n",
            "Validation data shape = (49881, 499)\n",
            "Test data shape = (49881, 499)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzd19ApjZJrk"
      },
      "source": [
        "##Model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ipvoDNwXzEp",
        "outputId": "7a9dba8d-57c5-4557-9a62-f849c66d393e"
      },
      "source": [
        "model = Model(inputs=[input_layer], outputs=output_layers)\n",
        "adam_optimizer = Adam()\n",
        "model.compile(\n",
        "    loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
        "    optimizer=adam_optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 499)]        0           []                               \n",
            "                                                                                                  \n",
            " m_mo_e (MMoE)                  [(None, 4),          24000       ['input_1[0][0]']                \n",
            "                                 (None, 4)]                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 8)            40          ['m_mo_e[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 8)            40          ['m_mo_e[0][1]']                 \n",
            "                                                                                                  \n",
            " income (Dense)                 (None, 2)            18          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " marital (Dense)                (None, 2)            18          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,116\n",
            "Trainable params: 24,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPHhbkeNZK_5"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pydeFqfhX-z9",
        "outputId": "99f6f61d-97ce-4a68-ff70-b78ea0787de5"
      },
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_label,\n",
        "    validation_data=(validation_data, validation_label),\n",
        "    callbacks=[\n",
        "        ROCCallback(\n",
        "            training_data=(train_data, train_label),\n",
        "            validation_data=(validation_data, validation_label),\n",
        "            test_data=(test_data, test_label)\n",
        "        )\n",
        "    ],\n",
        "    epochs=100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6228/6236 [============================>.] - ETA: 0s - loss: 0.4775 - income_loss: 0.1853 - marital_loss: 0.2922 - income_accuracy: 0.9378 - marital_accuracy: 0.8905ROC-AUC-income-Train: 0.9089 ROC-AUC-income-Validation: 0.9086 ROC-AUC-income-Test: 0.908\n",
            "ROC-AUC-marital-Train: 0.9667 ROC-AUC-marital-Validation: 0.9581 ROC-AUC-marital-Test: 0.9597\n",
            "6236/6236 [==============================] - 70s 11ms/step - loss: 0.4773 - income_loss: 0.1852 - marital_loss: 0.2921 - income_accuracy: 0.9378 - marital_accuracy: 0.8905 - val_loss: 0.3559 - val_income_loss: 0.1608 - val_marital_loss: 0.1951 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9321\n",
            "Epoch 2/100\n",
            "6234/6236 [============================>.] - ETA: 0s - loss: 0.3139 - income_loss: 0.1538 - marital_loss: 0.1600 - income_accuracy: 0.9379 - marital_accuracy: 0.9403ROC-AUC-income-Train: 0.9135 ROC-AUC-income-Validation: 0.9106 ROC-AUC-income-Test: 0.9105\n",
            "ROC-AUC-marital-Train: 0.9868 ROC-AUC-marital-Validation: 0.9716 ROC-AUC-marital-Test: 0.9711\n",
            "6236/6236 [==============================] - 55s 9ms/step - loss: 0.3138 - income_loss: 0.1538 - marital_loss: 0.1600 - income_accuracy: 0.9379 - marital_accuracy: 0.9404 - val_loss: 0.3680 - val_income_loss: 0.1561 - val_marital_loss: 0.2119 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9175\n",
            "Epoch 3/100\n",
            "6232/6236 [============================>.] - ETA: 0s - loss: 0.2829 - income_loss: 0.1501 - marital_loss: 0.1328 - income_accuracy: 0.9379 - marital_accuracy: 0.9451ROC-AUC-income-Train: 0.9166 ROC-AUC-income-Validation: 0.9142 ROC-AUC-income-Test: 0.914\n",
            "ROC-AUC-marital-Train: 0.9894 ROC-AUC-marital-Validation: 0.9745 ROC-AUC-marital-Test: 0.9738\n",
            "6236/6236 [==============================] - 67s 11ms/step - loss: 0.2829 - income_loss: 0.1501 - marital_loss: 0.1328 - income_accuracy: 0.9379 - marital_accuracy: 0.9451 - val_loss: 0.3745 - val_income_loss: 0.1744 - val_marital_loss: 0.2001 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9198\n",
            "Epoch 4/100\n",
            "6227/6236 [============================>.] - ETA: 0s - loss: 0.2747 - income_loss: 0.1473 - marital_loss: 0.1274 - income_accuracy: 0.9380 - marital_accuracy: 0.9467ROC-AUC-income-Train: 0.9166 ROC-AUC-income-Validation: 0.9167 ROC-AUC-income-Test: 0.9181\n",
            "ROC-AUC-marital-Train: 0.9903 ROC-AUC-marital-Validation: 0.9742 ROC-AUC-marital-Test: 0.9735\n",
            "6236/6236 [==============================] - 67s 11ms/step - loss: 0.2748 - income_loss: 0.1474 - marital_loss: 0.1275 - income_accuracy: 0.9379 - marital_accuracy: 0.9467 - val_loss: 0.3801 - val_income_loss: 0.1493 - val_marital_loss: 0.2308 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9108\n",
            "Epoch 5/100\n",
            "6229/6236 [============================>.] - ETA: 0s - loss: 0.2696 - income_loss: 0.1454 - marital_loss: 0.1241 - income_accuracy: 0.9379 - marital_accuracy: 0.9479ROC-AUC-income-Train: 0.9189 ROC-AUC-income-Validation: 0.9161 ROC-AUC-income-Test: 0.9156\n",
            "ROC-AUC-marital-Train: 0.9903 ROC-AUC-marital-Validation: 0.9703 ROC-AUC-marital-Test: 0.9696\n",
            "6236/6236 [==============================] - 61s 10ms/step - loss: 0.2696 - income_loss: 0.1454 - marital_loss: 0.1242 - income_accuracy: 0.9379 - marital_accuracy: 0.9479 - val_loss: 0.4096 - val_income_loss: 0.1795 - val_marital_loss: 0.2301 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9120\n",
            "Epoch 6/100\n",
            "6235/6236 [============================>.] - ETA: 0s - loss: 0.2669 - income_loss: 0.1441 - marital_loss: 0.1228 - income_accuracy: 0.9379 - marital_accuracy: 0.9485ROC-AUC-income-Train: 0.9222 ROC-AUC-income-Validation: 0.918 ROC-AUC-income-Test: 0.9176\n",
            "ROC-AUC-marital-Train: 0.9901 ROC-AUC-marital-Validation: 0.9709 ROC-AUC-marital-Test: 0.9698\n",
            "6236/6236 [==============================] - 68s 11ms/step - loss: 0.2669 - income_loss: 0.1441 - marital_loss: 0.1228 - income_accuracy: 0.9379 - marital_accuracy: 0.9485 - val_loss: 0.4106 - val_income_loss: 0.1814 - val_marital_loss: 0.2291 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9120\n",
            "Epoch 7/100\n",
            "6229/6236 [============================>.] - ETA: 0s - loss: 0.2637 - income_loss: 0.1421 - marital_loss: 0.1216 - income_accuracy: 0.9380 - marital_accuracy: 0.9485ROC-AUC-income-Train: 0.9318 ROC-AUC-income-Validation: 0.9283 ROC-AUC-income-Test: 0.9271\n",
            "ROC-AUC-marital-Train: 0.991 ROC-AUC-marital-Validation: 0.9701 ROC-AUC-marital-Test: 0.9692\n",
            "6236/6236 [==============================] - 65s 10ms/step - loss: 0.2637 - income_loss: 0.1421 - marital_loss: 0.1216 - income_accuracy: 0.9379 - marital_accuracy: 0.9485 - val_loss: 0.3823 - val_income_loss: 0.1602 - val_marital_loss: 0.2220 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9126\n",
            "Epoch 8/100\n",
            "6229/6236 [============================>.] - ETA: 0s - loss: 0.2609 - income_loss: 0.1406 - marital_loss: 0.1203 - income_accuracy: 0.9377 - marital_accuracy: 0.9487ROC-AUC-income-Train: 0.9322 ROC-AUC-income-Validation: 0.9302 ROC-AUC-income-Test: 0.9301\n",
            "ROC-AUC-marital-Train: 0.9904 ROC-AUC-marital-Validation: 0.969 ROC-AUC-marital-Test: 0.9683\n",
            "6236/6236 [==============================] - 68s 11ms/step - loss: 0.2609 - income_loss: 0.1407 - marital_loss: 0.1203 - income_accuracy: 0.9377 - marital_accuracy: 0.9487 - val_loss: 0.3887 - val_income_loss: 0.1577 - val_marital_loss: 0.2310 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9121\n",
            "Epoch 9/100\n",
            "6233/6236 [============================>.] - ETA: 0s - loss: 0.2552 - income_loss: 0.1402 - marital_loss: 0.1150 - income_accuracy: 0.9379 - marital_accuracy: 0.9508ROC-AUC-income-Train: 0.9285 ROC-AUC-income-Validation: 0.9243 ROC-AUC-income-Test: 0.9242\n",
            "ROC-AUC-marital-Train: 0.9918 ROC-AUC-marital-Validation: 0.9721 ROC-AUC-marital-Test: 0.971\n",
            "6236/6236 [==============================] - 67s 11ms/step - loss: 0.2552 - income_loss: 0.1402 - marital_loss: 0.1150 - income_accuracy: 0.9379 - marital_accuracy: 0.9508 - val_loss: 0.4179 - val_income_loss: 0.1718 - val_marital_loss: 0.2460 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9128\n",
            "Epoch 10/100\n",
            "6233/6236 [============================>.] - ETA: 0s - loss: 0.2523 - income_loss: 0.1396 - marital_loss: 0.1126 - income_accuracy: 0.9380 - marital_accuracy: 0.9517ROC-AUC-income-Train: 0.9372 ROC-AUC-income-Validation: 0.935 ROC-AUC-income-Test: 0.9341\n",
            "ROC-AUC-marital-Train: 0.9928 ROC-AUC-marital-Validation: 0.9721 ROC-AUC-marital-Test: 0.9713\n",
            "6236/6236 [==============================] - 71s 11ms/step - loss: 0.2523 - income_loss: 0.1396 - marital_loss: 0.1126 - income_accuracy: 0.9380 - marital_accuracy: 0.9517 - val_loss: 0.3783 - val_income_loss: 0.1529 - val_marital_loss: 0.2254 - val_income_accuracy: 0.9439 - val_marital_accuracy: 0.9158\n",
            "Epoch 11/100\n",
            "6230/6236 [============================>.] - ETA: 0s - loss: 0.2472 - income_loss: 0.1381 - marital_loss: 0.1091 - income_accuracy: 0.9393 - marital_accuracy: 0.9527ROC-AUC-income-Train: 0.9325 ROC-AUC-income-Validation: 0.9272 ROC-AUC-income-Test: 0.926\n",
            "ROC-AUC-marital-Train: 0.9926 ROC-AUC-marital-Validation: 0.9687 ROC-AUC-marital-Test: 0.9679\n",
            "6236/6236 [==============================] - 58s 9ms/step - loss: 0.2472 - income_loss: 0.1381 - marital_loss: 0.1091 - income_accuracy: 0.9393 - marital_accuracy: 0.9527 - val_loss: 0.4117 - val_income_loss: 0.1781 - val_marital_loss: 0.2336 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9079\n",
            "Epoch 12/100\n",
            "6231/6236 [============================>.] - ETA: 0s - loss: 0.2488 - income_loss: 0.1382 - marital_loss: 0.1106 - income_accuracy: 0.9387 - marital_accuracy: 0.9530ROC-AUC-income-Train: 0.9321 ROC-AUC-income-Validation: 0.9274 ROC-AUC-income-Test: 0.9254\n",
            "ROC-AUC-marital-Train: 0.9922 ROC-AUC-marital-Validation: 0.9681 ROC-AUC-marital-Test: 0.967\n",
            "6236/6236 [==============================] - 61s 10ms/step - loss: 0.2488 - income_loss: 0.1382 - marital_loss: 0.1105 - income_accuracy: 0.9387 - marital_accuracy: 0.9530 - val_loss: 0.4579 - val_income_loss: 0.2187 - val_marital_loss: 0.2392 - val_income_accuracy: 0.9403 - val_marital_accuracy: 0.9091\n",
            "Epoch 13/100\n",
            "6233/6236 [============================>.] - ETA: 0s - loss: 0.2460 - income_loss: 0.1375 - marital_loss: 0.1085 - income_accuracy: 0.9405 - marital_accuracy: 0.9537ROC-AUC-income-Train: 0.9307 ROC-AUC-income-Validation: 0.9276 ROC-AUC-income-Test: 0.9268\n",
            "ROC-AUC-marital-Train: 0.993 ROC-AUC-marital-Validation: 0.9709 ROC-AUC-marital-Test: 0.9699\n",
            "6236/6236 [==============================] - 68s 11ms/step - loss: 0.2460 - income_loss: 0.1375 - marital_loss: 0.1085 - income_accuracy: 0.9405 - marital_accuracy: 0.9537 - val_loss: 0.3814 - val_income_loss: 0.1561 - val_marital_loss: 0.2253 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9131\n",
            "Epoch 14/100\n",
            "6232/6236 [============================>.] - ETA: 0s - loss: 0.2418 - income_loss: 0.1358 - marital_loss: 0.1059 - income_accuracy: 0.9430 - marital_accuracy: 0.9550ROC-AUC-income-Train: 0.9288 ROC-AUC-income-Validation: 0.913 ROC-AUC-income-Test: 0.9126\n",
            "ROC-AUC-marital-Train: 0.9928 ROC-AUC-marital-Validation: 0.9711 ROC-AUC-marital-Test: 0.9703\n",
            "6236/6236 [==============================] - 59s 9ms/step - loss: 0.2418 - income_loss: 0.1358 - marital_loss: 0.1059 - income_accuracy: 0.9430 - marital_accuracy: 0.9550 - val_loss: 0.4394 - val_income_loss: 0.2149 - val_marital_loss: 0.2245 - val_income_accuracy: 0.9362 - val_marital_accuracy: 0.9133\n",
            "Epoch 15/100\n",
            "6231/6236 [============================>.] - ETA: 0s - loss: 0.2426 - income_loss: 0.1369 - marital_loss: 0.1057 - income_accuracy: 0.9435 - marital_accuracy: 0.9546ROC-AUC-income-Train: 0.9413 ROC-AUC-income-Validation: 0.9363 ROC-AUC-income-Test: 0.9353\n",
            "ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9708 ROC-AUC-marital-Test: 0.9698\n",
            "6236/6236 [==============================] - 58s 9ms/step - loss: 0.2427 - income_loss: 0.1369 - marital_loss: 0.1057 - income_accuracy: 0.9435 - marital_accuracy: 0.9545 - val_loss: 0.4333 - val_income_loss: 0.1994 - val_marital_loss: 0.2340 - val_income_accuracy: 0.9452 - val_marital_accuracy: 0.9097\n",
            "Epoch 16/100\n",
            "6229/6236 [============================>.] - ETA: 0s - loss: 0.2433 - income_loss: 0.1344 - marital_loss: 0.1090 - income_accuracy: 0.9453 - marital_accuracy: 0.9538ROC-AUC-income-Train: 0.938 ROC-AUC-income-Validation: 0.933 ROC-AUC-income-Test: 0.9337\n",
            "ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.971 ROC-AUC-marital-Test: 0.9701\n",
            "6236/6236 [==============================] - 69s 11ms/step - loss: 0.2433 - income_loss: 0.1344 - marital_loss: 0.1089 - income_accuracy: 0.9453 - marital_accuracy: 0.9538 - val_loss: 0.4088 - val_income_loss: 0.1785 - val_marital_loss: 0.2302 - val_income_accuracy: 0.9428 - val_marital_accuracy: 0.9057\n",
            "Epoch 17/100\n",
            "6233/6236 [============================>.] - ETA: 0s - loss: 0.2420 - income_loss: 0.1339 - marital_loss: 0.1080 - income_accuracy: 0.9452 - marital_accuracy: 0.9546ROC-AUC-income-Train: 0.934 ROC-AUC-income-Validation: 0.9299 ROC-AUC-income-Test: 0.9301\n",
            "ROC-AUC-marital-Train: 0.9928 ROC-AUC-marital-Validation: 0.9694 ROC-AUC-marital-Test: 0.9682\n",
            "6236/6236 [==============================] - 67s 11ms/step - loss: 0.2419 - income_loss: 0.1339 - marital_loss: 0.1080 - income_accuracy: 0.9452 - marital_accuracy: 0.9546 - val_loss: 0.4220 - val_income_loss: 0.1650 - val_marital_loss: 0.2570 - val_income_accuracy: 0.9405 - val_marital_accuracy: 0.9085\n",
            "Epoch 18/100\n",
            "6234/6236 [============================>.] - ETA: 0s - loss: 0.2416 - income_loss: 0.1358 - marital_loss: 0.1058 - income_accuracy: 0.9413 - marital_accuracy: 0.9547ROC-AUC-income-Train: 0.9399 ROC-AUC-income-Validation: 0.9349 ROC-AUC-income-Test: 0.9334\n",
            "ROC-AUC-marital-Train: 0.9933 ROC-AUC-marital-Validation: 0.9684 ROC-AUC-marital-Test: 0.9672\n",
            "6236/6236 [==============================] - 59s 9ms/step - loss: 0.2416 - income_loss: 0.1358 - marital_loss: 0.1058 - income_accuracy: 0.9413 - marital_accuracy: 0.9547 - val_loss: 0.4161 - val_income_loss: 0.1761 - val_marital_loss: 0.2400 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9093\n",
            "Epoch 19/100\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2387 - income_loss: 0.1360 - marital_loss: 0.1027 - income_accuracy: 0.9409 - marital_accuracy: 0.9559ROC-AUC-income-Train: 0.9314 ROC-AUC-income-Validation: 0.9267 ROC-AUC-income-Test: 0.9249\n",
            "ROC-AUC-marital-Train: 0.9938 ROC-AUC-marital-Validation: 0.9683 ROC-AUC-marital-Test: 0.9672\n",
            "6236/6236 [==============================] - 59s 9ms/step - loss: 0.2387 - income_loss: 0.1360 - marital_loss: 0.1027 - income_accuracy: 0.9409 - marital_accuracy: 0.9559 - val_loss: 0.4395 - val_income_loss: 0.1992 - val_marital_loss: 0.2404 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9020\n",
            "Epoch 20/100\n",
            "6234/6236 [============================>.] - ETA: 0s - loss: 0.2399 - income_loss: 0.1368 - marital_loss: 0.1031 - income_accuracy: 0.9413 - marital_accuracy: 0.9554ROC-AUC-income-Train: 0.9286 ROC-AUC-income-Validation: 0.9242 ROC-AUC-income-Test: 0.9219\n",
            "ROC-AUC-marital-Train: 0.9936 ROC-AUC-marital-Validation: 0.9683 ROC-AUC-marital-Test: 0.967\n",
            "6236/6236 [==============================] - 56s 9ms/step - loss: 0.2399 - income_loss: 0.1368 - marital_loss: 0.1031 - income_accuracy: 0.9413 - marital_accuracy: 0.9554 - val_loss: 0.4779 - val_income_loss: 0.2270 - val_marital_loss: 0.2509 - val_income_accuracy: 0.9430 - val_marital_accuracy: 0.8965\n",
            "Epoch 21/100\n",
            "6231/6236 [============================>.] - ETA: 0s - loss: 0.2384 - income_loss: 0.1344 - marital_loss: 0.1040 - income_accuracy: 0.9447 - marital_accuracy: 0.9548ROC-AUC-income-Train: 0.937 ROC-AUC-income-Validation: 0.9328 ROC-AUC-income-Test: 0.9335\n",
            "ROC-AUC-marital-Train: 0.9934 ROC-AUC-marital-Validation: 0.9673 ROC-AUC-marital-Test: 0.966\n",
            "6236/6236 [==============================] - 59s 9ms/step - loss: 0.2385 - income_loss: 0.1345 - marital_loss: 0.1041 - income_accuracy: 0.9447 - marital_accuracy: 0.9548 - val_loss: 0.4182 - val_income_loss: 0.1670 - val_marital_loss: 0.2512 - val_income_accuracy: 0.9414 - val_marital_accuracy: 0.9041\n",
            "Epoch 22/100\n",
            "6230/6236 [============================>.] - ETA: 0s - loss: 0.2371 - income_loss: 0.1351 - marital_loss: 0.1020 - income_accuracy: 0.9441 - marital_accuracy: 0.9554ROC-AUC-income-Train: 0.9418 ROC-AUC-income-Validation: 0.9356 ROC-AUC-income-Test: 0.935\n",
            "ROC-AUC-marital-Train: 0.9932 ROC-AUC-marital-Validation: 0.9671 ROC-AUC-marital-Test: 0.966\n",
            "6236/6236 [==============================] - 70s 11ms/step - loss: 0.2371 - income_loss: 0.1351 - marital_loss: 0.1020 - income_accuracy: 0.9441 - marital_accuracy: 0.9554 - val_loss: 0.4362 - val_income_loss: 0.1864 - val_marital_loss: 0.2499 - val_income_accuracy: 0.9427 - val_marital_accuracy: 0.9049\n",
            "Epoch 23/100\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2394 - income_loss: 0.1344 - marital_loss: 0.1051 - income_accuracy: 0.9461 - marital_accuracy: 0.9548ROC-AUC-income-Train: 0.9407 ROC-AUC-income-Validation: 0.9353 ROC-AUC-income-Test: 0.9339\n",
            "ROC-AUC-marital-Train: 0.9917 ROC-AUC-marital-Validation: 0.965 ROC-AUC-marital-Test: 0.9631\n",
            "6236/6236 [==============================] - 69s 11ms/step - loss: 0.2394 - income_loss: 0.1344 - marital_loss: 0.1051 - income_accuracy: 0.9461 - marital_accuracy: 0.9548 - val_loss: 0.4290 - val_income_loss: 0.1527 - val_marital_loss: 0.2763 - val_income_accuracy: 0.9438 - val_marital_accuracy: 0.9028\n",
            "Epoch 24/100\n",
            "6230/6236 [============================>.] - ETA: 0s - loss: 0.2349 - income_loss: 0.1326 - marital_loss: 0.1023 - income_accuracy: 0.9461 - marital_accuracy: 0.9554ROC-AUC-income-Train: 0.9421 ROC-AUC-income-Validation: 0.9379 ROC-AUC-income-Test: 0.9367\n",
            "ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9622 ROC-AUC-marital-Test: 0.9609\n",
            "6236/6236 [==============================] - 68s 11ms/step - loss: 0.2349 - income_loss: 0.1326 - marital_loss: 0.1023 - income_accuracy: 0.9461 - marital_accuracy: 0.9554 - val_loss: 0.4618 - val_income_loss: 0.1901 - val_marital_loss: 0.2718 - val_income_accuracy: 0.9456 - val_marital_accuracy: 0.9015\n",
            "Epoch 25/100\n",
            "6232/6236 [============================>.] - ETA: 0s - loss: 0.2355 - income_loss: 0.1335 - marital_loss: 0.1019 - income_accuracy: 0.9464 - marital_accuracy: 0.9557ROC-AUC-income-Train: 0.9429 ROC-AUC-income-Validation: 0.9388 ROC-AUC-income-Test: 0.9379\n",
            "ROC-AUC-marital-Train: 0.9935 ROC-AUC-marital-Validation: 0.9641 ROC-AUC-marital-Test: 0.9627\n",
            "6236/6236 [==============================] - 56s 9ms/step - loss: 0.2355 - income_loss: 0.1335 - marital_loss: 0.1019 - income_accuracy: 0.9464 - marital_accuracy: 0.9557 - val_loss: 0.4525 - val_income_loss: 0.1898 - val_marital_loss: 0.2627 - val_income_accuracy: 0.9421 - val_marital_accuracy: 0.9033\n",
            "Epoch 26/100\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2354 - income_loss: 0.1337 - marital_loss: 0.1017 - income_accuracy: 0.9462 - marital_accuracy: 0.9557ROC-AUC-income-Train: 0.9433 ROC-AUC-income-Validation: 0.937 ROC-AUC-income-Test: 0.9366\n",
            "ROC-AUC-marital-Train: 0.9938 ROC-AUC-marital-Validation: 0.9659 ROC-AUC-marital-Test: 0.9645\n",
            "6236/6236 [==============================] - 59s 9ms/step - loss: 0.2354 - income_loss: 0.1337 - marital_loss: 0.1017 - income_accuracy: 0.9462 - marital_accuracy: 0.9557 - val_loss: 0.4292 - val_income_loss: 0.1769 - val_marital_loss: 0.2523 - val_income_accuracy: 0.9428 - val_marital_accuracy: 0.9013\n",
            "Epoch 27/100\n",
            "6228/6236 [============================>.] - ETA: 0s - loss: 0.2339 - income_loss: 0.1331 - marital_loss: 0.1008 - income_accuracy: 0.9478 - marital_accuracy: 0.9561"
          ]
        }
      ]
    }
  ]
}